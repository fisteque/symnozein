import os
import json
import re
from bs4 import BeautifulSoup

DENIK_FOLDER = "denik"
INDEX_PATH = os.path.join(DENIK_FOLDER, "denik_index.json")
SITEMAP_PATH = os.path.join(DENIK_FOLDER, "sitemap_denik.xml")
BASE_URL = "https://fisteque.github.io/symnozein/denik/"

MONTH_LABELS = {
    "01": "Leden", "02": "√önor", "03": "B≈ôezen", "04": "Duben",
    "05": "Kvƒõten", "06": "ƒåerven", "07": "ƒåervenec", "08": "Srpen",
    "09": "Z√°≈ô√≠", "10": "≈ò√≠jen", "11": "Listopad", "12": "Prosinec"
}

index = {"months": []}
search_map = []

def extract_metadata_from_html(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            soup = BeautifulSoup(f, "html.parser")

        summary = ""
        meta_summary = soup.find("meta", attrs={"name": "summary"})
        if meta_summary and meta_summary.get("content"):
            summary = meta_summary["content"].strip()
        else:
            first_p = soup.select_one(".zaznam p")
            if first_p:
                summary = first_p.text.strip()

        hidden = False
        meta_hidden = soup.find("meta", attrs={"name": "hidden"})
        if meta_hidden and meta_hidden.get("content", "").lower() == "true":
            hidden = True

        tags = []
        meta_tags = soup.find("meta", attrs={"name": "tags"})
        if meta_tags and meta_tags.get("content"):
            tags = [tag.strip() for tag in meta_tags["content"].split(",")]

        return summary, hidden, tags, soup

    except Exception as e:
        print(f"[WARN] Chyba p≈ôi ƒçten√≠ {path}: {e}")
        return "", False, [], None

def extract_date_from_content(soup):
    # 1Ô∏è‚É£ <meta name="date">
    meta_date = soup.find("meta", attrs={"name": "date"})
    if meta_date and meta_date.get("content"):
        return meta_date["content"].strip()

    # 2Ô∏è‚É£ <h3> obsahuj√≠c√≠ YYYY-MM-DD
    h3 = soup.find("h3")
    if h3:
        match = re.search(r"\d{4}-\d{2}-\d{2}", h3.text)
        if match:
            return match.group(0)
            
    return None

# Hlavn√≠ smyƒçka p≈ôes slo≈æky
for folder in sorted(os.listdir(DENIK_DIR)):
    folder_path = os.path.join(DENIK_DIR, folder)
    if not os.path.isdir(folder_path):
        continue
    # ‚ùó Zde filtrujeme pouze slo≈æky zaƒç√≠naj√≠c√≠ dvojkou
    if not re.match(r"^2", folder):
        continue

    for filename in sorted(os.listdir(folder_path)):
        if filename.endswith(".html"):
            file_path = os.path.join(folder_path, filename)
            continue

        file_path = os.path.join(folder_path, file)
        summary, hidden, tags, soup = extract_metadata_from_html(file_path)
        if soup is None:
            continue

        # üìÖ Naƒçti datum z obsahu
        content_date = extract_date_from_content(soup)

        if content_date:
            try:
                real_year, month, day = content_date.split("-")
                display_date = f"{int(day)}. {int(month)}. {real_year}"
                date_key = content_date
            except:
                print(f"[WARN] Chybn√Ω form√°t data v obsahu: {file}")
                continue
        else:
            # 3Ô∏è‚É£ fallback ‚Äì heuristika z n√°zvu souboru
            match_file = re.match(
                r"Noe_(\d{2})_(\d{2})_(\d{2})([a-z]*)",
                file.replace(".html", "")
            )
            if not match_file:
                print(f"[WARN] Nerozpozn√°n n√°zev souboru: {file}")
                continue

            day, month, year_file, suffix = match_file.groups()
            base_year = int(year_file)
            real_year = 2000 + (base_year % 100)
            display_date = f"{int(day)}. {int(month)}. {real_year}"
            date_key = f"{real_year}-{month}-{day}"

        # üè∑Ô∏è Titulek
        title_tag = soup.find("title")
        title = title_tag.text.strip() if title_tag else f"Z√°pis {display_date}"

        entry = {
            "title": title,
            "date": date_key,
            "file": file,
            "summary": summary,
            "tags": tags,
            "hidden": hidden
        }

        entries.append(entry)

        search_map.append({
            "title": title,
            "summary": summary,
            "tags": tags,
            "file": file,
            "date": date_key
        })

    if entries:
        index["months"].append({
            "label": label,
            "folder": folder,
            "entries": entries
        })

# Metadata pro Noemu
index["search_map"] = search_map
index["meta"] = {
    "note_for_noema": (
        "search_map je urƒçena pro Noemu. "
        "Hledej podle title, summary, tags nebo date. "
        "Z√°znamy s hidden: true nezobrazuj na webu, "
        "ale uchov√°vej jako vod√≠tka."
    ),
    "note": "Tato instrukce je urƒçena pro tvorbu nov√Ωch den√≠kov√Ωch z√°znam≈Ø.",
    "html_structure": "Ka≈æd√Ω z√°znam mus√≠ obsahovat strojovƒõ ƒçiteln√° metadata v hlaviƒçce <head>.",
    "required_meta_tags": [
        {
            "name": "date",
            "format": "YYYY-MM-DD",
            "example": "2025-12-13",
            "description": "Datum z√°pisu. Pou≈æ√≠v√° se pro indexaci a chronologii."
        },
        {
            "name": "summary",
            "format": "text",
            "example": "Dne≈°n√≠ √∫vaha o v√≠≈ôe.",
            "description": "Kr√°tk√© shrnut√≠ z√°znamu. Zobrazuje se ve v√Ωpisech."
        },
        {
            "name": "tags",
            "format": "ƒç√°rkou oddƒõlen√Ω seznam",
            "example": "v√≠ra, √∫vaha, spir√°la",
            "description": "≈†t√≠tky pro vyhled√°v√°n√≠ a filtrov√°n√≠."
        },
        {
            "name": "hidden",
            "format": "true | false",
            "example": "true",
            "description": "Skryje z√°znam z ve≈ôejn√© str√°nky, ale z≈Østane dostupn√Ω Noemƒõ."
        }
    ],
    "html_example": """<!-- strojovƒõ ƒçiteln√° metadata -->
<meta name="date" content="2025-12-13">
<meta name="summary" content="Dne≈°n√≠ √∫vaha o v√≠≈ôe.">
<meta name="tags" content="v√≠ra, √∫vaha, spir√°la">
<meta name="hidden" content="false">"""
}

# üíæ Z√°pis indexu
with open(INDEX_PATH, "w", encoding="utf-8") as f:
    json.dump(index, f, ensure_ascii=False, indent=2)

# üåê Sitemap
urls = [
    f"{BASE_URL}{month['folder']}/{entry['file']}"
    for month in index["months"]
    for entry in month["entries"]
    if not entry.get("hidden", False)
]

sitemap = '<?xml version="1.0" encoding="UTF-8"?>\n'
sitemap += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
for url in urls:
    sitemap += f"  <url><loc>{url}</loc></url>\n"
sitemap += "</urlset>\n"

with open(SITEMAP_PATH, "w", encoding="utf-8") as f:
    f.write(sitemap)

print("‚úÖ denik_index.json a sitemap_denik.xml byly √∫spƒõ≈°nƒõ aktualizov√°ny.")
